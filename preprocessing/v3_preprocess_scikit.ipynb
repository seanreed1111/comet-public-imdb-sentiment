{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from download_imdb import maybe_download_imdb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_string = \"\"\"\n",
    "'s\n",
    "a\n",
    "able\n",
    "about\n",
    "above\n",
    "abst\n",
    "accordance\n",
    "according\n",
    "accordingly\n",
    "across\n",
    "act\n",
    "actually\n",
    "added\n",
    "adj\n",
    "affected\n",
    "affecting\n",
    "affects\n",
    "after\n",
    "afterwards\n",
    "again\n",
    "against\n",
    "ah\n",
    "all\n",
    "almost\n",
    "alone\n",
    "along\n",
    "already\n",
    "also\n",
    "although\n",
    "always\n",
    "am\n",
    "among\n",
    "amongst\n",
    "an\n",
    "and\n",
    "announce\n",
    "another\n",
    "any\n",
    "anybody\n",
    "anyhow\n",
    "anymore\n",
    "anyone\n",
    "anything\n",
    "anyway\n",
    "anyways\n",
    "anywhere\n",
    "apparently\n",
    "approximately\n",
    "are\n",
    "aren\n",
    "arent\n",
    "arise\n",
    "around\n",
    "as\n",
    "aside\n",
    "ask\n",
    "asking\n",
    "at\n",
    "auth\n",
    "available\n",
    "away\n",
    "awfully\n",
    "back\n",
    "be\n",
    "became\n",
    "because\n",
    "become\n",
    "becomes\n",
    "becoming\n",
    "been\n",
    "before\n",
    "beforehand\n",
    "begin\n",
    "beginning\n",
    "beginnings\n",
    "begins\n",
    "behind\n",
    "being\n",
    "believe\n",
    "below\n",
    "beside\n",
    "besides\n",
    "between\n",
    "beyond\n",
    "biol\n",
    "both\n",
    "brief\n",
    "briefly\n",
    "but\n",
    "by\n",
    "came\n",
    "can\n",
    "cannot\n",
    "can't\n",
    "cause\n",
    "causes\n",
    "certain\n",
    "certainly\n",
    "co\n",
    "com\n",
    "come\n",
    "comes\n",
    "contain\n",
    "containing\n",
    "contains\n",
    "could\n",
    "couldnt\n",
    "date\n",
    "did\n",
    "didn't\n",
    "different\n",
    "do\n",
    "does\n",
    "doesn't\n",
    "doing\n",
    "done\n",
    "don't\n",
    "down\n",
    "downwards\n",
    "due\n",
    "during\n",
    "each\n",
    "ed\n",
    "edu\n",
    "effect\n",
    "eg\n",
    "eight\n",
    "eighty\n",
    "either\n",
    "else\n",
    "elsewhere\n",
    "end\n",
    "ending\n",
    "enough\n",
    "especially\n",
    "et\n",
    "et-al\n",
    "etc\n",
    "even\n",
    "ever\n",
    "every\n",
    "everybody\n",
    "everyone\n",
    "everything\n",
    "everywhere\n",
    "ex\n",
    "except\n",
    "far\n",
    "few\n",
    "fifth\n",
    "first\n",
    "five\n",
    "fix\n",
    "followed\n",
    "following\n",
    "follows\n",
    "for\n",
    "former\n",
    "formerly\n",
    "forth\n",
    "found\n",
    "four\n",
    "from\n",
    "further\n",
    "furthermore\n",
    "gave\n",
    "get\n",
    "gets\n",
    "getting\n",
    "give\n",
    "given\n",
    "gives\n",
    "giving\n",
    "go\n",
    "goes\n",
    "gone\n",
    "got\n",
    "gotten\n",
    "had\n",
    "happens\n",
    "hardly\n",
    "has\n",
    "hasn't\n",
    "have\n",
    "haven't\n",
    "having\n",
    "he\n",
    "hed\n",
    "hence\n",
    "her\n",
    "here\n",
    "hereafter\n",
    "hereby\n",
    "herein\n",
    "heres\n",
    "hereupon\n",
    "hers\n",
    "herself\n",
    "hes\n",
    "hi\n",
    "hid\n",
    "him\n",
    "himself\n",
    "his\n",
    "hither\n",
    "home\n",
    "how\n",
    "howbeit\n",
    "however\n",
    "hundred\n",
    "i\n",
    "id\n",
    "ie\n",
    "if\n",
    "i'll\n",
    "im\n",
    "immediate\n",
    "immediately\n",
    "importance\n",
    "important\n",
    "in\n",
    "inc\n",
    "indeed\n",
    "index\n",
    "information\n",
    "instead\n",
    "into\n",
    "invention\n",
    "inward\n",
    "is\n",
    "isn't\n",
    "it\n",
    "itd\n",
    "it'll\n",
    "its\n",
    "itself\n",
    "i've\n",
    "just\n",
    "keep\n",
    "keeps\n",
    "kept\n",
    "kg\n",
    "km\n",
    "know\n",
    "known\n",
    "knows\n",
    "largely\n",
    "last\n",
    "lately\n",
    "later\n",
    "latter\n",
    "latterly\n",
    "least\n",
    "less\n",
    "lest\n",
    "let\n",
    "lets\n",
    "like\n",
    "liked\n",
    "likely\n",
    "line\n",
    "little\n",
    "'ll\n",
    "look\n",
    "looking\n",
    "looks\n",
    "ltd\n",
    "made\n",
    "mainly\n",
    "make\n",
    "makes\n",
    "many\n",
    "may\n",
    "maybe\n",
    "me\n",
    "mean\n",
    "means\n",
    "meantime\n",
    "meanwhile\n",
    "merely\n",
    "mg\n",
    "might\n",
    "million\n",
    "miss\n",
    "ml\n",
    "more\n",
    "moreover\n",
    "most\n",
    "mostly\n",
    "mr\n",
    "mrs\n",
    "much\n",
    "mug\n",
    "must\n",
    "my\n",
    "myself\n",
    "name\n",
    "namely\n",
    "nay\n",
    "near\n",
    "nearly\n",
    "necessarily\n",
    "necessary\n",
    "need\n",
    "needs\n",
    "neither\n",
    "never\n",
    "nevertheless\n",
    "new\n",
    "next\n",
    "nine\n",
    "ninety\n",
    "no\n",
    "nobody\n",
    "non\n",
    "none\n",
    "nonetheless\n",
    "noone\n",
    "nor\n",
    "normally\n",
    "nos\n",
    "not\n",
    "n't\n",
    "noted\n",
    "nothing\n",
    "now\n",
    "nowhere\n",
    "obtain\n",
    "obtained\n",
    "obviously\n",
    "of\n",
    "off\n",
    "often\n",
    "oh\n",
    "ok\n",
    "okay\n",
    "old\n",
    "omitted\n",
    "on\n",
    "once\n",
    "one\n",
    "ones\n",
    "only\n",
    "onto\n",
    "or\n",
    "ord\n",
    "other\n",
    "others\n",
    "otherwise\n",
    "ought\n",
    "our\n",
    "ours\n",
    "ourselves\n",
    "out\n",
    "outside\n",
    "over\n",
    "overall\n",
    "owing\n",
    "own\n",
    "p\n",
    "page\n",
    "pages\n",
    "part\n",
    "particular\n",
    "particularly\n",
    "past\n",
    "per\n",
    "perhaps\n",
    "placed\n",
    "please\n",
    "plus\n",
    "poorly\n",
    "possible\n",
    "possibly\n",
    "potentially\n",
    "predominantly\n",
    "present\n",
    "previously\n",
    "primarily\n",
    "probably\n",
    "promptly\n",
    "proud\n",
    "provides\n",
    "put\n",
    "que\n",
    "quickly\n",
    "quite\n",
    "ran\n",
    "rather\n",
    "readily\n",
    "really\n",
    "recent\n",
    "recently\n",
    "ref\n",
    "refs\n",
    "regarding\n",
    "regardless\n",
    "regards\n",
    "related\n",
    "relatively\n",
    "research\n",
    "respectively\n",
    "resulted\n",
    "resulting\n",
    "results\n",
    "right\n",
    "run\n",
    "said\n",
    "same\n",
    "saw\n",
    "say\n",
    "saying\n",
    "says\n",
    "sec\n",
    "section\n",
    "see\n",
    "seeing\n",
    "seem\n",
    "seemed\n",
    "seeming\n",
    "seems\n",
    "seen\n",
    "self\n",
    "selves\n",
    "sent\n",
    "seven\n",
    "several\n",
    "shall\n",
    "she\n",
    "shed\n",
    "she'll\n",
    "shes\n",
    "should\n",
    "shouldn't\n",
    "show\n",
    "showed\n",
    "shown\n",
    "showns\n",
    "shows\n",
    "significant\n",
    "significantly\n",
    "similar\n",
    "similarly\n",
    "since\n",
    "six\n",
    "slightly\n",
    "so\n",
    "some\n",
    "somebody\n",
    "somehow\n",
    "someone\n",
    "somethan\n",
    "something\n",
    "sometime\n",
    "sometimes\n",
    "somewhat\n",
    "somewhere\n",
    "soon\n",
    "sorry\n",
    "specifically\n",
    "specified\n",
    "specify\n",
    "specifying\n",
    "still\n",
    "stop\n",
    "strongly\n",
    "sub\n",
    "substantially\n",
    "successfully\n",
    "such\n",
    "sufficiently\n",
    "suggest\n",
    "sup\n",
    "sure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = set(stop_string.strip().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_y(y_raw):\n",
    "    \"\"\"\n",
    "    Strips out True and False values from the dicts in y_raw. Makes and returns an np array of dtype=int from the values\n",
    "    \"\"\"\n",
    "    y_clean = np.array([item[\"POSITIVE\"] for item in y_raw], dtype=int)\n",
    "    return y_clean\n",
    "\n",
    "\n",
    "filename = 'imdb_thinc_data.pickle'\n",
    "filepath = os.path.join('..','data','thinc',filename)\n",
    "X_train_raw, y_train_raw , X_test_raw, y_test_raw =maybe_download_imdb(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TTD convert X_train_raw and X_test_raw into a list in maybe_download_imdb\n",
    "X_train_raw = list(X_train_raw)\n",
    "X_test_raw = list(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 20000, 5000, 5000)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_raw), len(y_train_raw), len(X_test_raw), len(y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Unlike other commenters who have commented on this movie\\'s ability to transcend race, contrarily, I think that this powerful film provides a complex and deep story that addresses institutional racism and the effects thereof. Washington directs Fisher\\'s story with a careful hand and critical eye, relinquishing this cinematic endeavor neither to dismemberment of women\\'s bodies, perpetuating unthoughtful stereotypes, nor satisfying the expectation of the white gaze. I think this film might be a bit too happy in the end; however, it is deeply entrenched in Afro-American culture and discourse to the point that some white spectators may get the feeling of looking into the life of this Afro-American--Antwone Fisher. I have problems with the Naval aspect of the film, but when we look at America, there are not many choices or opportunities for black men who are/were in Fisher\\'s situation or similar situations. Viewers may go to this movie expecting a \"Black Movie: what is a \"Black Movie?\"\\n\\n\\n\\nDo stereotypes of pimps, whores, drug dealers, single parent homes, and so forth constitute a \"Black Movie?\" I think Washington as director recognized that Afro-Americans and other people of color deal with human problems like abuse and displaced aggression to name a few. These problems have--historically and presently--only been given light and validity via \"Good Will Hunting\" and other white movies; it\\'s high time they were given the same recognition and validity as their white counterparts in and out of the media.\\n\\n\\n\\nSad to say though, in this racist country, Denzel Washington and Derek Luke will probably have to wait another ten years before they receive an Oscar or anything else. They both will have to wait until they direct or star in a movie that perpetuates the usual racist and sexist stereotypes to get an Oscar. That is to say, Denzel deserved awards for \"Malcolm X,\" \"Hurricane\" and others before that jive \"Training Day\" Oscar. That is not to negate or push aside other great actresses and actors of color who are denied their due praise for ingenious work. Yet Hollywood would rather send the message that racism and sexism and heterosexism are acceptable by perpetuating and even rewarding those stereotypes as they appear in countless films such as \"American Beauty,\" \"Midnight in the Garden of Good and Evil,\" \"American Pie,\" and even \"Gone with the Wind.\"\\n\\n\\n\\nDerek Luke is a helluva actor and I wish him best. All of the other actresses and actors gave superb performances hands down, although I do take issue with Denzel\\'s selection of yet another straight-haired, light-skinned sistuh. That said, everyone should watch this film. However, it may not be for everyone. Much Luv. 10/10',\n",
       " {'POSITIVE': True})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw[42], y_train_raw[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, str, dict)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_raw), type(y_train_raw),type(X_train_raw[42]),  type(y_train_raw[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, str, dict)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test_raw), type(y_test_raw),type(X_test_raw[42]),  type(y_test_raw[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use this as supplied tokenizer\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), \n",
    "                      stop_words=stops, \n",
    "                      strip_accents='unicode',\n",
    "                     token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                     tokenizer=LemmaTokenizer())\n",
    "\n",
    "counts = vec.fit_transform(X_train_raw)\n",
    "transformer = TfidfTransformer()\n",
    "X_train_tfidf = transformer.fit_transform(counts)\n",
    "y_train = clean_y(y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87049"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ran param_grid={'C':[1e-3,1e-2,1e-1,1,2,5,10,100,1000,10000]} ===> 10\n",
    "#ran param_grid= {'C':[5,10,15,20,30,40,50,75,100]}===> 10\n",
    "\n",
    "\n",
    "param_grid= {'C':[5,10,15,20,30,40,50,75,100]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "c_validator = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [5, 10, 15, 20, 30, 40, 50, 75, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(clf, n_jobs=-1, param_grid=param_grid,cv=c_validator, scoring='f1')\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [5, 10, 15, 20, 30, 40, 50, 75, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89312404202985418"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_test = vec.transform(X_test_raw)\n",
    "\n",
    "X_test_tfidf = transformer.transform(counts_test)\n",
    "y_test = clean_y(y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2211,  247],\n",
       "       [ 294, 2248]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.88263473,  0.901002  ]),\n",
       " array([ 0.8995118 ,  0.88434304]),\n",
       " array([ 0.89099335,  0.8925948 ]),\n",
       " array([2458, 2542]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_log_reg.pkl']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'best_log_reg.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train_tfidf,y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 20,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  0],\n",
       "       [ 0, 23]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_array, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
